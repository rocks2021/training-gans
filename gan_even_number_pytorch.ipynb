{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan_even_number_pytorch",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rocks2021/training-gans/blob/main/gan_even_number_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Colab is coded by Nicolas Bertagnolli. "
      ],
      "metadata": {
        "id": "5q4qgeBk4iKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple, List\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "ibxO6MPIOEzZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_binary_list_from_int(number: int) -> List[int]:\n",
        "    \"\"\"Creates a list of the binary representation of a positive integer\n",
        "    Args:\n",
        "        number: An integer\n",
        "    Returns:\n",
        "        The binary representation of the provided positive integer number as a list.\n",
        "    \"\"\"\n",
        "    if number < 0 or type(number) is not int:\n",
        "        raise ValueError(\"Only Positive integers are allowed\")\n",
        "\n",
        "    return [int(x) for x in list(bin(number))[2:]]\n",
        "\n",
        "\n",
        "def generate_even_data(\n",
        "    max_int: int, batch_size: int = 16\n",
        ") -> Tuple[List[int], List[List[int]]]:\n",
        "    \"\"\"An infinite data generator which yields\n",
        "    Args:\n",
        "        max_int: The maximum input integer value\n",
        "        batch_size: The size of the training batch.\n",
        "    Returns:\n",
        "        A Tuple with the labels and the input data.\n",
        "        labels:\n",
        "        data:\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the number of binary places needed to represent the maximum number\n",
        "    max_length = int(math.log(max_int, 2))\n",
        "\n",
        "    # Sample batch_size number of integers in range 0-max_int\n",
        "    sampled_integers = np.random.randint(0, int(max_int / 2), batch_size)\n",
        "\n",
        "    # create a list of labels all ones because all numbers are even\n",
        "    labels = [1] * batch_size\n",
        "\n",
        "    # Generate a list of binary numbers for training.\n",
        "    data = [create_binary_list_from_int(int(x * 2)) for x in sampled_integers]\n",
        "    data = [([0] * (max_length - len(x))) + x for x in data]\n",
        "\n",
        "    return labels, data\n",
        "\n",
        "\n",
        "def convert_float_matrix_to_int_list(\n",
        "    float_matrix: np.array, threshold: float = 0.5\n",
        ") -> List[int]:\n",
        "    \"\"\"Converts generated output in binary list form to a list of integers\n",
        "    Args:\n",
        "        float_matrix: A matrix of values between 0 and 1 which we want to threshold and convert to\n",
        "            integers\n",
        "        threshold: The cutoff value for 0 and 1 thresholding.\n",
        "    Returns:\n",
        "        A list of integers.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        int(\"\".join([str(int(y)) for y in x]), 2) for x in float_matrix >= threshold\n",
        "    ]"
      ],
      "metadata": {
        "id": "BCRodpw2OGg1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_length: int):\n",
        "        super(Generator, self).__init__()\n",
        "        self.dense_layer = nn.Linear(int(input_length), int(input_length))\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.activation(self.dense_layer(x))\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_length: int):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.dense = nn.Linear(int(input_length), 1)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.activation(self.dense(x))\n",
        "\n",
        "\n",
        "class DCGenerator(nn.Module):\n",
        "    def __init__(self, input_length: int, n_channels: int,  num_base_filters: Optional[int]):\n",
        "        super(DCGenerator, self).__init__()\n",
        "\n",
        "        # Calculates the total number of layers\n",
        "        number_of_layers = int(math.log(self.img_cols, 2) - 3)\n",
        "\n",
        "        if self.num_base_filters is None:\n",
        "            num_base_filters = 32 * 2 ** number_of_layers\n",
        "\n",
        "        # Create the list to hold all sequential layers\n",
        "        self.layers_list = []\n",
        "\n",
        "        # Add the initial layer\n",
        "        self.layers_list.append(nn.Linear(input_length, num_base_filters * 8 * 8))\n",
        "        self.layers_list.append(nn.ReLU())\n",
        "\n",
        "        # Add a scaled number of layers\n",
        "        self.layers_list.append(nn.BatchNorm2d(128))\n",
        "        self.layers_list.append(nn.Upsample(scale_factor=2))\n",
        "        self.layers_list.append(nn.Conv2d(128, 128, 3, stride=1, padding=1))\n",
        "        self.layers_list.append(nn.BatchNorm2d(128, 0.8))\n",
        "        self.layers_list.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.layers_list.append(nn.Upsample(scale_factor=2))\n",
        "        self.layers_list.append(nn.Conv2d(128, 64, 3, stride=1, padding=1))\n",
        "        self.layers_list.append(nn.BatchNorm2d(64, 0.8))\n",
        "        self.layers_list.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.layers_list.append(nn.Conv2d(64, n_channels, 3, stride=1, padding=1))\n",
        "        self.layers_list.append(nn.Tanh())\n",
        "\n",
        "        self.layers = nn.ModuleList(self.layers_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCDiscriminator(nn.Module):\n",
        "    def __init__(self, image_size: int, input_channels: int):\n",
        "        super(DCDiscriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 32, 3, stride=2, padding=1),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
        "            nn.ELU(),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.ELU(),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(256 * 8 * 8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "0GUzPYG1OO9r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    max_int: int = 128,\n",
        "    batch_size: int = 16,\n",
        "    training_steps: int = 500,\n",
        "    learning_rate: float = 0.001,\n",
        "    print_output_every_n_steps: int = 10,\n",
        ") -> Tuple[nn.Module]:\n",
        "    \"\"\"Trains the even GAN\n",
        "    Args:\n",
        "        max_int: The maximum integer our dataset goes to.  It is used to set the size of the binary\n",
        "            lists\n",
        "        batch_size: The number of examples in a training batch\n",
        "        training_steps: The number of steps to train on.\n",
        "        learning_rate: The learning rate for the generator and discriminator\n",
        "        print_output_every_n_steps: The number of training steps before we print generated output\n",
        "    Returns:\n",
        "        generator: The trained generator model\n",
        "        discriminator: The trained discriminator model\n",
        "    \"\"\"\n",
        "    input_length = int(math.log(max_int, 2))\n",
        "\n",
        "    # Models\n",
        "    generator = Generator(input_length)\n",
        "    discriminator = Discriminator(input_length)\n",
        "\n",
        "    # Optimizers\n",
        "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "    discriminator_optimizer = torch.optim.Adam(\n",
        "        discriminator.parameters(), lr=learning_rate\n",
        "    )\n",
        "\n",
        "    # loss\n",
        "    loss = nn.BCELoss()\n",
        "\n",
        "    for i in range(training_steps):\n",
        "        # zero the gradients on each iteration\n",
        "        generator_optimizer.zero_grad()\n",
        "\n",
        "        # Create noisy input for generator\n",
        "        # Need float type instead of int\n",
        "        noise = torch.randint(0, 2, size=(batch_size, input_length)).float()\n",
        "        generated_data = generator(noise)\n",
        "\n",
        "        # Generate examples of even real data\n",
        "        true_labels, true_data = generate_even_data(max_int, batch_size=batch_size)\n",
        "        true_labels = torch.tensor(true_labels).float()\n",
        "        true_labels = true_labels.unsqueeze(1)\n",
        "        true_data = torch.tensor(true_data).float()\n",
        "\n",
        "        # Train the generator\n",
        "        # We invert the labels here and don't train the discriminator because we want the generator\n",
        "        # to make things the discriminator classifies as true.\n",
        "        generator_discriminator_out = discriminator(generated_data)\n",
        "        generator_loss = loss(generator_discriminator_out, true_labels)\n",
        "        generator_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "\n",
        "        # Train the discriminator on the true/generated data\n",
        "        discriminator_optimizer.zero_grad()\n",
        "        true_discriminator_out = discriminator(true_data)\n",
        "        true_discriminator_loss = loss(true_discriminator_out, true_labels)\n",
        "\n",
        "        # add .detach() here think about this\n",
        "        generator_discriminator_out = discriminator(generated_data.detach())\n",
        "        # generator_discriminator_loss = loss(\n",
        "        #     generator_discriminator_out, torch.zeros(batch_size)\n",
        "        # )\n",
        "        generator_discriminator_loss = loss(generator_discriminator_out, torch.zeros(batch_size).unsqueeze(1))\n",
        "        discriminator_loss = (\n",
        "            true_discriminator_loss + generator_discriminator_loss\n",
        "        ) / 2\n",
        "        discriminator_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "        if i % print_output_every_n_steps == 0:\n",
        "            print(convert_float_matrix_to_int_list(generated_data))\n",
        "\n",
        "    return generator, discriminator\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My2CQTD_OTcI",
        "outputId": "4a370aa9-431b-4d2f-a1c2-5c8383195e44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30, 62, 28, 30, 20, 28, 30, 30, 31, 25, 29, 31, 30, 29, 30, 29]\n",
            "[29, 30, 62, 30, 30, 30, 28, 29, 29, 63, 21, 28, 62, 30, 30, 63]\n",
            "[61, 29, 63, 29, 20, 62, 63, 63, 29, 30, 30, 30, 30, 62, 31, 31]\n",
            "[63, 63, 62, 63, 22, 29, 31, 30, 61, 30, 62, 62, 29, 31, 62, 29]\n",
            "[59, 30, 31, 29, 63, 30, 63, 30, 63, 63, 31, 29, 62, 63, 58, 63]\n",
            "[63, 31, 58, 63, 30, 29, 31, 63, 63, 62, 61, 29, 30, 31, 61, 63]\n",
            "[27, 31, 47, 63, 62, 29, 29, 47, 63, 59, 63, 30, 59, 31, 63, 63]\n",
            "[63, 30, 59, 47, 29, 30, 22, 63, 63, 31, 62, 59, 63, 31, 59, 31]\n",
            "[29, 27, 47, 47, 15, 59, 63, 59, 47, 58, 27, 63, 46, 59, 63, 59]\n",
            "[14, 46, 63, 47, 30, 59, 59, 43, 59, 63, 27, 59, 31, 30, 63, 46]\n",
            "[63, 59, 43, 46, 59, 27, 47, 47, 59, 59, 47, 59, 25, 47, 47, 43]\n",
            "[111, 26, 47, 59, 11, 107, 11, 47, 47, 27, 43, 47, 43, 18, 59, 43]\n",
            "[42, 42, 42, 42, 29, 27, 43, 43, 27, 59, 43, 111, 43, 43, 47, 43]\n",
            "[43, 43, 27, 59, 43, 47, 43, 27, 42, 107, 107, 42, 107, 27, 127, 43]\n",
            "[43, 43, 107, 43, 107, 43, 106, 43, 43, 27, 43, 27, 107, 43, 107, 26]\n",
            "[107, 27, 31, 43, 43, 43, 43, 106, 43, 106, 43, 43, 43, 43, 43, 107]\n",
            "[59, 43, 107, 27, 59, 107, 43, 107, 42, 43, 10, 42, 107, 43, 11, 106]\n",
            "[107, 42, 107, 43, 107, 59, 107, 90, 10, 43, 43, 107, 107, 43, 27, 107]\n",
            "[43, 43, 106, 107, 106, 107, 107, 107, 10, 107, 43, 107, 107, 43, 107, 107]\n",
            "[43, 106, 107, 43, 43, 106, 27, 43, 43, 107, 43, 106, 27, 107, 107, 11]\n",
            "[106, 43, 107, 11, 10, 107, 106, 42, 107, 107, 107, 43, 43, 107, 43, 106]\n",
            "[107, 75, 107, 106, 106, 42, 107, 106, 107, 75, 107, 107, 107, 107, 27, 106]\n",
            "[107, 106, 107, 107, 107, 75, 43, 42, 106, 107, 106, 107, 10, 42, 27, 11]\n",
            "[106, 107, 106, 11, 106, 107, 106, 106, 59, 107, 107, 107, 42, 106, 106, 107]\n",
            "[106, 106, 107, 107, 106, 43, 106, 107, 107, 107, 107, 107, 106, 107, 106, 107]\n",
            "[106, 106, 107, 106, 107, 106, 106, 107, 42, 42, 106, 106, 106, 107, 42, 106]\n",
            "[107, 106, 106, 106, 106, 106, 107, 107, 107, 107, 106, 43, 106, 106, 107, 106]\n",
            "[74, 106, 107, 106, 107, 107, 106, 106, 106, 74, 106, 74, 43, 106, 106, 106]\n",
            "[106, 74, 107, 106, 11, 107, 74, 106, 43, 106, 107, 107, 107, 43, 106, 106]\n",
            "[107, 11, 106, 74, 107, 106, 106, 42, 106, 106, 106, 106, 106, 106, 106, 74]\n",
            "[106, 106, 42, 106, 107, 106, 106, 106, 107, 106, 106, 106, 106, 106, 106, 106]\n",
            "[106, 106, 106, 106, 107, 106, 106, 106, 106, 106, 106, 42, 106, 74, 106, 11]\n",
            "[106, 106, 106, 106, 106, 106, 74, 106, 74, 106, 74, 106, 106, 74, 106, 106]\n",
            "[106, 107, 106, 74, 106, 66, 106, 26, 74, 106, 107, 107, 106, 106, 106, 74]\n",
            "[106, 74, 106, 42, 106, 106, 26, 74, 106, 106, 106, 106, 106, 106, 74, 107]\n",
            "[106, 106, 106, 106, 106, 106, 42, 74, 106, 106, 106, 106, 106, 106, 106, 74]\n",
            "[106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 74, 106, 106, 106, 106]\n",
            "[106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106]\n",
            "[78, 42, 106, 106, 106, 78, 106, 106, 106, 106, 106, 74, 106, 106, 106, 106]\n",
            "[106, 110, 106, 106, 106, 106, 78, 106, 74, 106, 106, 110, 110, 106, 106, 106]\n",
            "[106, 106, 106, 106, 106, 106, 106, 106, 10, 106, 106, 74, 106, 106, 74, 78]\n",
            "[98, 110, 106, 110, 74, 106, 98, 106, 106, 74, 110, 110, 106, 106, 110, 74]\n",
            "[106, 106, 74, 106, 110, 110, 110, 106, 110, 78, 78, 106, 110, 106, 74, 106]\n",
            "[106, 110, 110, 110, 110, 110, 106, 106, 106, 106, 106, 106, 110, 106, 110, 106]\n",
            "[110, 106, 106, 110, 106, 70, 110, 78, 78, 106, 106, 66, 102, 110, 110, 98]\n",
            "[106, 110, 106, 110, 110, 70, 110, 110, 98, 110, 106, 106, 110, 70, 110, 110]\n",
            "[78, 78, 74, 102, 110, 110, 70, 110, 110, 110, 78, 110, 110, 74, 106, 70]\n",
            "[78, 78, 70, 78, 78, 78, 110, 102, 110, 78, 78, 110, 110, 74, 110, 102]\n",
            "[106, 78, 110, 110, 110, 110, 78, 70, 110, 110, 78, 110, 110, 70, 110, 78]\n",
            "[110, 102, 110, 110, 102, 78, 102, 78, 102, 70, 70, 102, 106, 110, 78, 78]\n"
          ]
        }
      ]
    }
  ]
}