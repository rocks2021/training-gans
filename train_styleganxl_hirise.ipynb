{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_styleganxl_hirise.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFrUZ69XZGyp"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision -y\n",
        "!pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "1Al1j_WFE_Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm==0.4.12 ftfy==6.1.1 ninja==1.10.2 numpy==1.20 click==8.0 pillow==8.3.1 scipy==1.7.1 requests==2.26.0 tqdm==4.62.2 matplotlib==3.4.2 \\\n",
        "imageio==2.9.0 dill==0.3.4 psutil==5.8.0 regex==2022.3.15 imgui==1.3.0 glfw==2.2.0 pyopengl==3.1.5 imageio-ffmpeg==0.4.3 pyspng opensimplex\n",
        "\n"
      ],
      "metadata": {
        "id": "gU63mlh6f0oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dPwWyKKIJwpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "rMMJXu0xJ9bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/autonomousvision/stylegan_xl.git"
      ],
      "metadata": {
        "id": "s8xoYZKXJ__i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/stylegan_xl"
      ],
      "metadata": {
        "id": "OJZQd4sCKXnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --outdir=./training-runs/ --cfg=stylegan3-t --data=/content/drive/MyDrive/hirise60kgan.zip \\\n",
        "    --gpus=1 --batch=32 --snap 2 --batch-gpu 8 --kimg 10000 --cbase 16384 --syn_layers 7 \\\n",
        "    #--resume=/content/drive/MyDrive/stylegan_xl/training_runs/00000-stylegan3-t-hirise60kgan-gpus1-batch32/network-snapshot.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5Ms9gFmKQf1",
        "outputId": "830c2686-c493-45f4-e43e-3b79af1590e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3_resetting.Generator\",\n",
            "    \"z_dim\": 64,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"rand_embedding\": false,\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 1024,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801,\n",
            "    \"conv_kernel\": 3,\n",
            "    \"use_radial_filters\": false,\n",
            "    \"num_layers\": 7\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/hirise60kgan.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 58888,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 128,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 10000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 2,\n",
            "  \"network_snapshot_ticks\": 2,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"restart_every\": 999999999,\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"pg_modules.discriminator.ProjectedDiscriminator\",\n",
            "    \"backbones\": [\n",
            "      \"deit_base_distilled_patch16_224\",\n",
            "      \"tf_efficientnet_lite0\"\n",
            "    ],\n",
            "    \"diffaug\": true,\n",
            "    \"interp224\": true,\n",
            "    \"backbone_kwargs\": {\n",
            "      \"cout\": 64,\n",
            "      \"expand\": true,\n",
            "      \"proj_type\": 2,\n",
            "      \"num_discs\": 4,\n",
            "      \"cond\": false\n",
            "    }\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.ProjectedGANLoss\",\n",
            "    \"blur_init_sigma\": 2,\n",
            "    \"blur_fade_kimg\": 300,\n",
            "    \"pl_weight\": 2.0,\n",
            "    \"pl_no_weight_grad\": true,\n",
            "    \"style_mixing_prob\": 0.0,\n",
            "    \"cls_weight\": 0.0,\n",
            "    \"cls_model\": \"deit_small_distilled_patch16_224\",\n",
            "    \"train_head_only\": false\n",
            "  },\n",
            "  \"run_dir\": \"./training-runs/00000-stylegan3-t-hirise60kgan-gpus1-batch32\"\n",
            "}\n",
            "\n",
            "Output directory:    ./training-runs/00000-stylegan3-t-hirise60kgan-gpus1-batch32\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   10000 kimg\n",
            "Dataset path:        /content/drive/MyDrive/hirise60kgan.zip\n",
            "Dataset size:        58888 images\n",
            "Dataset resolution:  128\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  58888\n",
            "Image shape: [3, 128, 128]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "loaded imagenet embeddings from in_embeddings/tf_efficientnet_lite0.pkl: Embedding(1000, 320)\n",
            "Resuming from \"./training-runs/00000-stylegan3-t-hirise60kgan-gpus1-batch32/network-snapshot.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                    Parameters  Buffers  Output shape        Datatype\n",
            "---                          ---         ---      ---                 ---     \n",
            "mapping.fc0                  33280       -        [8, 512]            float32 \n",
            "mapping.fc1                  262656      -        [8, 512]            float32 \n",
            "mapping                      320000      512      [8, 9, 512]         float32 \n",
            "synthesis.input.affine       2052        -        [8, 4]              float32 \n",
            "synthesis.input              1048576     3081     [8, 1024, 36, 36]   float32 \n",
            "synthesis.L0_36_1024.affine  525312      -        [8, 1024]           float32 \n",
            "synthesis.L0_36_1024         9438208     25       [8, 1024, 36, 36]   float16 \n",
            "synthesis.L1_36_1024.affine  525312      -        [8, 1024]           float32 \n",
            "synthesis.L1_36_1024         9438208     25       [8, 1024, 36, 36]   float16 \n",
            "synthesis.L2_52_1024.affine  525312      -        [8, 1024]           float32 \n",
            "synthesis.L2_52_1024         9438208     37       [8, 1024, 52, 52]   float16 \n",
            "synthesis.L3_84_1024.affine  525312      -        [8, 1024]           float32 \n",
            "synthesis.L3_84_1024         9438208     37       [8, 1024, 84, 84]   float16 \n",
            "synthesis.L4_148_512.affine  525312      -        [8, 1024]           float32 \n",
            "synthesis.L4_148_512         4719104     37       [8, 512, 148, 148]  float16 \n",
            "synthesis.L5_148_256.affine  262656      -        [8, 512]            float32 \n",
            "synthesis.L5_148_256         1179904     25       [8, 256, 148, 148]  float16 \n",
            "synthesis.L6_128_256.affine  131328      -        [8, 256]            float32 \n",
            "synthesis.L6_128_256         590080      25       [8, 256, 128, 128]  float16 \n",
            "synthesis.L7_128_3.affine    131328      -        [8, 256]            float32 \n",
            "synthesis.L7_128_3           771         1        [8, 3, 128, 128]    float16 \n",
            "synthesis                    -           -        [8, 3, 128, 128]    float32 \n",
            "---                          ---         ---      ---                 ---     \n",
            "Total                        49061127    3805     -                   -       \n",
            "\n",
            "\n",
            "ProjectedDiscriminator                                                                                Parameters  Buffers  Output shape       Datatype\n",
            "---                                                                                                   ---         ---      ---                ---     \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.patch_embed.proj                    590592      -        [8, 768, 14, 14]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.pos_drop                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.0.norm1                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.0.attn                       2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.0.norm2                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.0.mlp                        4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.0                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.1.norm1                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.1.attn                       2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.1.norm2                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.1.mlp                        4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.1                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.2.norm1                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.2.attn                       2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.2.norm2                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.2.mlp                        4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.2                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.3.norm1                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.3.attn                       2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.3.norm2                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.3.mlp                        4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.3                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.4.norm1                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.4.attn                       2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.4.norm2                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.4.mlp                        4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.4                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.5.norm1                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.5.attn                       2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.5.norm2                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.5.mlp                        4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.5                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.6.norm1                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.6.attn                       2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.6.norm2                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.6.mlp                        4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.6                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.7.norm1                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.7.attn                       2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.7.norm2                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.7.mlp                        4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.7                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.8.norm1                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.8.attn                       2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.8.norm2                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.8.mlp                        4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.8                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.9.norm1                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.9.attn                       2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.9.norm2                      1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.9.mlp                        4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.9                            -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.10.norm1                     1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.10.attn                      2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.10.norm2                     1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.10.mlp                       4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.10                           -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.11.norm1                     1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.11.attn                      2362368     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.11.norm2                     1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.11.mlp                       4722432     -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.blocks.11                           -           -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.model.norm                                1536        -        [8, 198, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer1.0                                  -           -        [8, 196, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer1.1                                  -           -        [8, 768, 196]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer1.0                                  -           -        [8, 196, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer2.1                                  -           -        [8, 768, 196]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer1.0                                  -           -        [8, 196, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer3.1                                  -           -        [8, 768, 196]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer1.0                                  -           -        [8, 196, 768]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer4.1                                  -           -        [8, 768, 196]      float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer1.3                                  73824       -        [8, 96, 14, 14]    float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer1.4                                  147552      -        [8, 96, 56, 56]    float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer2.3                                  147648      -        [8, 192, 14, 14]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer2.4                                  147648      -        [8, 192, 28, 28]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer3.3                                  295296      -        [8, 384, 14, 14]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer4.3                                  590592      -        [8, 768, 14, 14]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.pretrained.layer4.4                                  5309184     -        [8, 768, 7, 7]     float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer0_ccm                                   6208        -        [8, 64, 56, 56]    float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer1_ccm                                   24704       -        [8, 128, 28, 28]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer2_ccm                                   98560       -        [8, 256, 14, 14]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer3_ccm                                   393728      -        [8, 512, 7, 7]     float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer3_csm.out_conv                          131328      -        [8, 256, 14, 14]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer2_csm.skip_add.activation_post_process  -           -        [8, 256, 14, 14]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer2_csm.out_conv                          32896       -        [8, 128, 28, 28]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer1_csm.skip_add.activation_post_process  -           -        [8, 128, 28, 28]   float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer1_csm.out_conv                          8256        -        [8, 64, 56, 56]    float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer0_csm.skip_add.activation_post_process  -           -        [8, 64, 56, 56]    float32 \n",
            "feature_networks.deit_base_distilled_patch16_224.scratch.layer0_csm.out_conv                          4160        -        [8, 64, 112, 112]  float32 \n",
            "feature_networks.deit_base_distilled_patch16_224                                                      1691600     -        -                  -       \n",
            "discriminators.deit_base_distilled_patch16_224.mini_discs.0.main                                      2829120     19269    [8, 1, 4, 4]       float32 \n",
            "discriminators.deit_base_distilled_patch16_224.mini_discs.1.main                                      2763392     18052    [8, 1, 4, 4]       float32 \n",
            "discriminators.deit_base_distilled_patch16_224.mini_discs.2.main                                      2631936     16643    [8, 1, 4, 4]       float32 \n",
            "discriminators.deit_base_distilled_patch16_224.mini_discs.3.main                                      2106880     13826    [8, 1, 4, 4]       float32 \n",
            "discriminators.deit_base_distilled_patch16_224                                                        -           -        [8, 64]            float32 \n",
            "feature_networks.tf_efficientnet_lite0.pretrained.layer0.0                                            864         -        [8, 32, 112, 112]  float32 \n",
            "feature_networks.tf_efficientnet_lite0.pretrained.layer0.1                                            64          65       [8, 32, 112, 112]  float32 \n",
            "feature_networks.tf_efficientnet_lite0.pretrained.layer0.3                                            896         98       [8, 16, 112, 112]  float32 \n",
            "feature_networks.tf_efficientnet_lite0.pretrained.layer0.4                                            13968       1062     [8, 24, 56, 56]    float32 \n",
            "feature_networks.tf_efficientnet_lite0.pretrained.layer1.0                                            39712       1702     [8, 40, 28, 28]    float32 \n",
            "feature_networks.tf_efficientnet_lite0.pretrained.layer2.0                                            198480      5289     [8, 80, 14, 14]    float32 \n",
            "feature_networks.tf_efficientnet_lite0.pretrained.layer2.1                                            446784      7977     [8, 112, 14, 14]   float32 \n",
            "feature_networks.tf_efficientnet_lite0.pretrained.layer3.0                                            1652640     18060    [8, 192, 7, 7]     float32 \n",
            "feature_networks.tf_efficientnet_lite0.pretrained.layer3.1                                            605440      5251     [8, 320, 7, 7]     float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer0_ccm                                             1600        -        [8, 64, 56, 56]    float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer1_ccm                                             5248        -        [8, 128, 28, 28]   float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer2_ccm                                             28928       -        [8, 256, 14, 14]   float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer3_ccm                                             164352      -        [8, 512, 7, 7]     float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer3_csm.out_conv                                    131328      -        [8, 256, 14, 14]   float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer2_csm.skip_add.activation_post_process            -           -        [8, 256, 14, 14]   float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer2_csm.out_conv                                    32896       -        [8, 128, 28, 28]   float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer1_csm.skip_add.activation_post_process            -           -        [8, 128, 28, 28]   float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer1_csm.out_conv                                    8256        -        [8, 64, 56, 56]    float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer0_csm.skip_add.activation_post_process            -           -        [8, 64, 56, 56]    float32 \n",
            "feature_networks.tf_efficientnet_lite0.scratch.layer0_csm.out_conv                                    4160        -        [8, 64, 112, 112]  float32 \n",
            "discriminators.tf_efficientnet_lite0.mini_discs.0.main                                                2829120     19269    [8, 1, 4, 4]       float32 \n",
            "discriminators.tf_efficientnet_lite0.mini_discs.1.main                                                2763392     18052    [8, 1, 4, 4]       float32 \n",
            "discriminators.tf_efficientnet_lite0.mini_discs.2.main                                                2631936     16643    [8, 1, 4, 4]       float32 \n",
            "discriminators.tf_efficientnet_lite0.mini_discs.3.main                                                2106880     13826    [8, 1, 4, 4]       float32 \n",
            "discriminators.tf_efficientnet_lite0                                                                  -           -        [8, 64]            float32 \n",
            "<top-level>:0                                                                                         -           -        [64]               float32 \n",
            "<top-level>:1                                                                                         -           -        [64]               float32 \n",
            "<top-level>:2                                                                                         -           -        [64]               float32 \n",
            "<top-level>:3                                                                                         -           -        [64]               float32 \n",
            "<top-level>:4                                                                                         -           -        [64]               float32 \n",
            "<top-level>:5                                                                                         -           -        [64]               float32 \n",
            "<top-level>:6                                                                                         -           -        [64]               float32 \n",
            "<top-level>:7                                                                                         -           -        [64]               float32 \n",
            "<top-level>:8                                                                                         -           -        [64]               float32 \n",
            "<top-level>:9                                                                                         -           -        [64]               float32 \n",
            "<top-level>:10                                                                                        -           -        [64]               float32 \n",
            "<top-level>:11                                                                                        -           -        [64]               float32 \n",
            "<top-level>:12                                                                                        -           -        [64]               float32 \n",
            "<top-level>:13                                                                                        -           -        [64]               float32 \n",
            "<top-level>:14                                                                                        -           -        [64]               float32 \n",
            "<top-level>:15                                                                                        -           -        [64]               float32 \n",
            "---                                                                                                   ---         ---      ---                ---     \n",
            "Total                                                                                                 118748048   175084   -                  -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_small_distilled_patch16_224-649709d9.pth\" to /root/.cache/torch/hub/checkpoints/deit_small_distilled_patch16_224-649709d9.pth\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 10000 kimg...\n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "tick 2     kimg 16.0     time 19m 35s      sec/tick 977.6   sec/kimg 244.39  maintenance 197.5  cpumem 8.06   gpumem 8.41   reserved 11.17  augment 0.000\n",
            "Evaluating metrics...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "70/10"
      ],
      "metadata": {
        "id": "gtxJK2ZwGaxm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}